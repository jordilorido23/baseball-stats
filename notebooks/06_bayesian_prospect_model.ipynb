{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Hierarchical Model for Prospect Evaluation\n",
    "\n",
    "**Statistical Approach:** Hierarchical Bayesian logistic regression with partial pooling across positions\n",
    "\n",
    "**Why Bayesian?**\n",
    "1. **Uncertainty Quantification**: Full posterior distributions, not just point estimates\n",
    "2. **Hierarchical Structure**: Borrows strength across positions (partial pooling)\n",
    "3. **Small Sample Handling**: Shrinkage prevents overfitting with limited data\n",
    "4. **Interpretability**: Clear probabilistic interpretation for front office decisions\n",
    "5. **Principled Inference**: Proper propagation of uncertainty through predictions\n",
    "\n",
    "**Model Structure:**\n",
    "```\n",
    "Level 1 (Player-level):\n",
    "  MLB_Success_i ~ Bernoulli(p_i)\n",
    "  logit(p_i) = α_position[i] + X_i @ β\n",
    "\n",
    "Level 2 (Position-level):\n",
    "  α_j ~ Normal(μ_α, σ_α)  # Partial pooling across positions\n",
    "\n",
    "Level 3 (Hyperpriors):\n",
    "  μ_α ~ Normal(0, 2)\n",
    "  σ_α ~ HalfNormal(1)\n",
    "  β_k ~ Normal(0, 1)\n",
    "```\n",
    "\n",
    "**Key Advantage:** Positions with sparse data (catchers, utility players) borrow information from the overall population while still capturing position-specific effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Bayesian modeling\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "# Our modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data import MiLBFetcher\n",
    "from src.models import ProspectPredictor\n",
    "from src.models.bayesian_prospect_model import BayesianProspectModel\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "az.style.use('arviz-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(f\"PyMC version: {pm.__version__}\")\n",
    "print(f\"ArviZ version: {az.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "We'll use AAA data from recent seasons to predict MLB arrival probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch AAA data\n",
    "milb = MiLBFetcher()\n",
    "\n",
    "# Get multiple seasons for more training data\n",
    "seasons = [2021, 2022, 2023, 2024]\n",
    "aaa_data = []\n",
    "\n",
    "for year in seasons:\n",
    "    try:\n",
    "        df = milb.get_batting_stats(year, level='AAA')\n",
    "        df['season'] = year\n",
    "        aaa_data.append(df)\n",
    "        print(f\"Fetched {len(df)} players from {year} AAA\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch {year}: {e}\")\n",
    "\n",
    "# Combine seasons\n",
    "aaa_df = pd.concat(aaa_data, ignore_index=True)\n",
    "\n",
    "# Filter to qualified batters\n",
    "aaa_df = aaa_df[aaa_df['PA'] >= 100].copy()\n",
    "\n",
    "print(f\"\\nTotal prospects: {len(aaa_df)}\")\n",
    "print(f\"Unique players: {aaa_df['Name'].nunique()}\")\n",
    "print(f\"\\nPositions: {aaa_df['Pos'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "predictor = ProspectPredictor()\n",
    "aaa_featured = predictor.engineer_features(aaa_df, level='AAA', player_type='batter')\n",
    "\n",
    "print(\"Engineered features:\")\n",
    "print(aaa_featured.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create MLB Success Labels\n",
    "\n",
    "For demonstration, we'll create synthetic labels based on performance thresholds.\n",
    "In production, you would match to actual MLB outcomes using player IDs.\n",
    "\n",
    "**Success Definition:** Players with wRC+ > 100 and Age < 26 (young performers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create success labels (in production: match to MLB outcomes via playerid)\n",
    "# For now: high performance + young age = higher success probability\n",
    "aaa_featured['mlb_success'] = (\n",
    "    (aaa_featured['wRC+'] >= 110) & \n",
    "    (aaa_featured['Age'] <= 26) &\n",
    "    (aaa_featured['PA'] >= 150)\n",
    ").astype(int)\n",
    "\n",
    "# Add some noise to make it realistic\n",
    "np.random.seed(42)\n",
    "noise = np.random.binomial(1, 0.15, size=len(aaa_featured))\n",
    "aaa_featured['mlb_success'] = (aaa_featured['mlb_success'].values + noise) % 2\n",
    "\n",
    "print(f\"Success rate: {aaa_featured['mlb_success'].mean():.1%}\")\n",
    "print(f\"\\nSuccess by position:\")\n",
    "print(aaa_featured.groupby('Pos')['mlb_success'].agg(['mean', 'count']).sort_values('mean', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "bayes_model = BayesianProspectModel(random_seed=42)\n",
    "\n",
    "# Prepare data with hierarchical structure\n",
    "feature_cols = [\n",
    "    'Age', 'wRC+', 'K%', 'BB%', 'ISO', 'BABIP',\n",
    "    'age_differential', 'k_bb_ratio', 'elite_wrc',\n",
    "    'elite_discipline', 'has_power'\n",
    "]\n",
    "\n",
    "data = bayes_model.prepare_data(\n",
    "    milb_df=aaa_featured,\n",
    "    success_col='mlb_success',\n",
    "    position_col='Pos',\n",
    "    feature_cols=feature_cols,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(data['y_train'])}\")\n",
    "print(f\"Test samples: {len(data['y_test'])}\")\n",
    "print(f\"Number of positions: {data['n_positions']}\")\n",
    "print(f\"Positions: {data['positions']}\")\n",
    "print(f\"Number of features: {data['n_features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit Hierarchical Bayesian Model\n",
    "\n",
    "**MCMC Sampling:** Using NUTS (No-U-Turn Sampler)\n",
    "- 4 chains for convergence diagnostics\n",
    "- 2000 draws per chain\n",
    "- 1000 tuning steps for adaptation\n",
    "\n",
    "**Expected runtime:** 2-5 minutes depending on hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit model with MCMC\n",
    "trace, diagnostics = bayes_model.fit(\n",
    "    data=data,\n",
    "    chains=4,\n",
    "    draws=2000,\n",
    "    tune=1000,\n",
    "    target_accept=0.95,\n",
    "    return_diagnostics=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONVERGENCE DIAGNOSTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Converged: {diagnostics['converged']}\")\n",
    "print(f\"Max R-hat: {diagnostics['max_rhat']:.4f} (should be < 1.01)\")\n",
    "print(f\"Min ESS (bulk): {diagnostics['min_ess_bulk']:.0f} (should be > 400)\")\n",
    "print(f\"Min ESS (tail): {diagnostics['min_ess_tail']:.0f} (should be > 400)\")\n",
    "print(f\"Divergences: {diagnostics['n_divergences']} (should be 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Posterior Analysis\n",
    "\n",
    "### 5.1 Trace Plots (Convergence Diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MCMC traces\n",
    "fig = bayes_model.plot_posterior_diagnostics(\n",
    "    var_names=['mu_alpha', 'sigma_alpha'],\n",
    "    save_path='../blog/figures/bayesian_trace_hyperparameters.png'\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Left: Posterior distributions (should be smooth and unimodal)\")\n",
    "print(\"- Right: MCMC traces (should be 'fuzzy caterpillars' with no trends)\")\n",
    "print(\"- Good mixing = chains overlap and explore the same regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Feature Effects (Beta Coefficients)\n",
    "\n",
    "Which statistics are most predictive of MLB success?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature effects with credible intervals\n",
    "feature_effects = bayes_model.get_feature_effects(credible_interval=0.95)\n",
    "\n",
    "print(\"\\nFEATURE EFFECTS (Standardized Coefficients)\")\n",
    "print(\"=\"*80)\n",
    "print(feature_effects.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "y_pos = np.arange(len(feature_effects))\n",
    "\n",
    "# Plot means\n",
    "ax.scatter(feature_effects['effect_mean'], y_pos, s=100, zorder=3)\n",
    "\n",
    "# Plot credible intervals\n",
    "for i, row in feature_effects.iterrows():\n",
    "    color = 'darkgreen' if row['significant'] else 'gray'\n",
    "    ax.plot([row['effect_lower'], row['effect_upper']], [i, i], \n",
    "            color=color, linewidth=2, alpha=0.7)\n",
    "\n",
    "ax.axvline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(feature_effects['feature'])\n",
    "ax.set_xlabel('Effect Size (standardized)', fontsize=12)\n",
    "ax.set_title('Feature Effects on MLB Success Probability\\n(95% Credible Intervals)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../blog/figures/bayesian_feature_effects.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Positive effects increase MLB success probability\")\n",
    "print(\"- Significant = credible interval doesn't include 0 (green)\")\n",
    "print(\"- Wider intervals = more uncertainty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Position-Specific Effects\n",
    "\n",
    "Baseline MLB success rates by position (partial pooling estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract position effects\n",
    "position_effects = bayes_model.get_position_effects(credible_interval=0.95)\n",
    "\n",
    "print(\"\\nPOSITION-SPECIFIC BASELINE SUCCESS RATES\")\n",
    "print(\"=\"*80)\n",
    "print(position_effects.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "y_pos = np.arange(len(position_effects))\n",
    "\n",
    "# Plot baseline probabilities\n",
    "ax.barh(y_pos, position_effects['baseline_prob'], alpha=0.6)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(position_effects['position'])\n",
    "ax.set_xlabel('Baseline MLB Success Probability', fontsize=12)\n",
    "ax.set_title('Position-Specific Success Rates (Partial Pooling Estimates)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, prob in enumerate(position_effects['baseline_prob']):\n",
    "    ax.text(prob + 0.02, i, f\"{prob:.1%}\", va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../blog/figures/bayesian_position_effects.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(\"Positions with fewer data points are 'shrunk' toward the overall mean.\")\n",
    "print(\"This prevents overfitting on sparse position categories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions with Uncertainty\n",
    "\n",
    "Generate predictions on held-out test set with full posterior uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "X_test_df = pd.DataFrame(\n",
    "    data['X_test'], \n",
    "    columns=bayes_model.feature_names\n",
    ")\n",
    "\n",
    "predictions = bayes_model.predict(\n",
    "    X_new=X_test_df,\n",
    "    position_new=data['pos_test'],\n",
    "    credible_interval=0.95,\n",
    "    n_samples=1000\n",
    ")\n",
    "\n",
    "# Add true labels\n",
    "predictions['true_label'] = data['y_test']\n",
    "\n",
    "print(\"\\nPREDICTIONS (First 20 prospects)\")\n",
    "print(\"=\"*80)\n",
    "print(predictions.head(20).to_string())\n",
    "\n",
    "# Calibration analysis\n",
    "predictions['prob_bin'] = pd.cut(\n",
    "    predictions['prob_mean'], \n",
    "    bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    labels=['0-20%', '20-40%', '40-60%', '60-80%', '80-100%']\n",
    ")\n",
    "\n",
    "calibration = predictions.groupby('prob_bin').agg({\n",
    "    'true_label': ['mean', 'count'],\n",
    "    'prob_mean': 'mean'\n",
    "})\n",
    "calibration.columns = ['observed_rate', 'n', 'predicted_prob']\n",
    "\n",
    "print(\"\\nCALIBRATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction uncertainty\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Prediction distribution by true label\n",
    "ax = axes[0]\n",
    "predictions_success = predictions[predictions['true_label'] == 1]['prob_mean']\n",
    "predictions_failure = predictions[predictions['true_label'] == 0]['prob_mean']\n",
    "\n",
    "ax.hist(predictions_failure, bins=20, alpha=0.6, label='Did not succeed', color='red')\n",
    "ax.hist(predictions_success, bins=20, alpha=0.6, label='Succeeded', color='green')\n",
    "ax.set_xlabel('Predicted Probability', fontsize=12)\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.set_title('Prediction Distribution by Actual Outcome', fontsize=13, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Right: Calibration curve\n",
    "ax = axes[1]\n",
    "ax.scatter(calibration['predicted_prob'], calibration['observed_rate'], \n",
    "          s=calibration['n']*2, alpha=0.6, color='blue')\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Perfect calibration')\n",
    "ax.set_xlabel('Predicted Probability', fontsize=12)\n",
    "ax.set_ylabel('Observed Success Rate', fontsize=12)\n",
    "ax.set_title('Calibration Curve\\n(size = sample size)', fontsize=13, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../blog/figures/bayesian_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Uncertainty Quantification\n",
    "\n",
    "One of the key advantages: we can identify high-uncertainty predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify high-uncertainty predictions\n",
    "predictions_sorted = predictions.sort_values('interval_width', ascending=False)\n",
    "\n",
    "print(\"\\nHIGH UNCERTAINTY PREDICTIONS (Wide Credible Intervals)\")\n",
    "print(\"=\"*80)\n",
    "print(\"These prospects have uncertain projections - need more scouting info!\")\n",
    "print(predictions_sorted[[\n",
    "    'prob_mean', 'prob_lower', 'prob_upper', 'interval_width', 'true_label'\n",
    "]].head(10).to_string())\n",
    "\n",
    "print(\"\\n\\nLOW UNCERTAINTY PREDICTIONS (Narrow Credible Intervals)\")\n",
    "print(\"=\"*80)\n",
    "print(\"These prospects have confident projections.\")\n",
    "predictions_sorted = predictions.sort_values('interval_width', ascending=True)\n",
    "print(predictions_sorted[[\n",
    "    'prob_mean', 'prob_lower', 'prob_upper', 'interval_width', 'true_label'\n",
    "]].head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize uncertainty\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Sort by predicted probability\n",
    "pred_plot = predictions.sort_values('prob_mean').reset_index(drop=True)\n",
    "x = np.arange(len(pred_plot))\n",
    "\n",
    "# Plot credible intervals\n",
    "ax.fill_between(\n",
    "    x,\n",
    "    pred_plot['prob_lower'],\n",
    "    pred_plot['prob_upper'],\n",
    "    alpha=0.3,\n",
    "    color='blue',\n",
    "    label='95% Credible Interval'\n",
    ")\n",
    "\n",
    "# Plot means\n",
    "ax.plot(x, pred_plot['prob_mean'], color='darkblue', linewidth=1.5, label='Posterior Mean')\n",
    "\n",
    "# Mark true outcomes\n",
    "success_idx = pred_plot[pred_plot['true_label'] == 1].index\n",
    "failure_idx = pred_plot[pred_plot['true_label'] == 0].index\n",
    "ax.scatter(success_idx, pred_plot.loc[success_idx, 'prob_mean'], \n",
    "          color='green', s=20, alpha=0.5, label='True Success', zorder=3)\n",
    "ax.scatter(failure_idx, pred_plot.loc[failure_idx, 'prob_mean'], \n",
    "          color='red', s=20, alpha=0.5, label='True Failure', zorder=3)\n",
    "\n",
    "ax.set_xlabel('Prospect (sorted by predicted probability)', fontsize=12)\n",
    "ax.set_ylabel('MLB Success Probability', fontsize=12)\n",
    "ax.set_title('Prospect Predictions with Uncertainty Bands', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../blog/figures/bayesian_uncertainty_bands.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(\"Wide credible intervals = model is uncertain (need more data/scouting)\")\n",
    "print(\"Narrow intervals = model is confident in the projection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Comparison: Hierarchical vs Pooled\n",
    "\n",
    "Demonstrate the value of hierarchical structure using WAIC (Widely Applicable Information Criterion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compare to non-hierarchical baseline\n",
    "comparison = bayes_model.compare_to_pooled_model(data)\n",
    "\n",
    "print(\"\\nMODEL COMPARISON (WAIC)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Hierarchical Model WAIC: {comparison['hierarchical_waic']:.2f}\")\n",
    "print(f\"Pooled Model WAIC: {comparison['pooled_waic']:.2f}\")\n",
    "print(f\"\\nImprovement: {comparison['improvement']:.2f}\")\n",
    "print(\"\\nLower WAIC = better model\")\n",
    "print(\"Hierarchical structure captures position-specific patterns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Production Use: Rank 2025 AAA Prospects\n",
    "\n",
    "Apply trained model to current AAA population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 2024 AAA data (most recent)\n",
    "aaa_2024 = milb.get_batting_stats(2024, level='AAA')\n",
    "aaa_2024 = aaa_2024[aaa_2024['PA'] >= 100].copy()\n",
    "\n",
    "# Engineer features\n",
    "aaa_2024_featured = predictor.engineer_features(aaa_2024, level='AAA', player_type='batter')\n",
    "\n",
    "# Prepare for prediction\n",
    "X_2024 = aaa_2024_featured[bayes_model.feature_names].fillna(\n",
    "    aaa_2024_featured[bayes_model.feature_names].median()\n",
    ")\n",
    "\n",
    "# Map positions\n",
    "positions_2024 = aaa_2024_featured['Pos'].fillna('Unknown')\n",
    "position_idx_2024 = positions_2024.map(bayes_model.position_mapping).fillna(0).astype(int)\n",
    "\n",
    "# Predict\n",
    "prospects_2024 = bayes_model.predict(\n",
    "    X_new=X_2024,\n",
    "    position_new=position_idx_2024.values,\n",
    "    credible_interval=0.95,\n",
    "    n_samples=1000\n",
    ")\n",
    "\n",
    "# Add player info\n",
    "prospects_2024['Name'] = aaa_2024_featured['Name'].values\n",
    "prospects_2024['Age'] = aaa_2024_featured['Age'].values\n",
    "prospects_2024['Pos'] = aaa_2024_featured['Pos'].values\n",
    "prospects_2024['wRC+'] = aaa_2024_featured['wRC+'].values\n",
    "prospects_2024['PA'] = aaa_2024_featured['PA'].values\n",
    "\n",
    "# Rank by probability\n",
    "top_prospects = prospects_2024.sort_values('prob_mean', ascending=False)\n",
    "\n",
    "print(\"\\nTOP 30 AAA PROSPECTS (2024 Season)\")\n",
    "print(\"=\"*100)\n",
    "print(top_prospects[[\n",
    "    'Name', 'Age', 'Pos', 'wRC+', 'PA',\n",
    "    'prob_mean', 'prob_lower', 'prob_upper'\n",
    "]].head(30).to_string(index=False))\n",
    "\n",
    "# Export for front office\n",
    "top_prospects[[\n",
    "    'Name', 'Age', 'Pos', 'wRC+', 'PA',\n",
    "    'prob_mean', 'prob_lower', 'prob_upper', 'interval_width'\n",
    "]].to_csv('../data/bayesian_prospect_rankings_2024.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Rankings saved to: data/bayesian_prospect_rankings_2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways\n",
    "\n",
    "### Why This Matters for Front Office Decision-Making:\n",
    "\n",
    "1. **Uncertainty Quantification**\n",
    "   - Traditional models give single probabilities: \"65% chance of MLB success\"\n",
    "   - Bayesian approach: \"65% with 95% CI [45%, 82%]\" \n",
    "   - Wide intervals = more risk, need additional scouting info\n",
    "\n",
    "2. **Hierarchical Structure**\n",
    "   - Catchers and utility players have less data\n",
    "   - Partial pooling prevents overfitting on sparse positions\n",
    "   - Borrows strength from overall population while capturing position specifics\n",
    "\n",
    "3. **Interpretability**\n",
    "   - Clear feature effects with credible intervals\n",
    "   - \"wRC+ has a 0.42 effect (95% CI: [0.31, 0.53])\"\n",
    "   - Statistically significant effects identified automatically\n",
    "\n",
    "4. **Small Sample Robustness**\n",
    "   - Regularization priors prevent overfitting\n",
    "   - Shrinkage helps with prospects with limited PA\n",
    "\n",
    "5. **Model Comparison**\n",
    "   - WAIC demonstrates hierarchical structure improves predictions\n",
    "   - Principled Bayesian model selection\n",
    "\n",
    "### Production Applications:\n",
    "\n",
    "- **Trade Deadline:** Rank available AAA call-ups with uncertainty bands\n",
    "- **Rule 5 Draft:** Identify undervalued prospects (high prob, low exposure)\n",
    "- **40-Man Roster Decisions:** Probability thresholds for protection\n",
    "- **Scouting Allocation:** Focus on high-uncertainty prospects (wide CIs)\n",
    "- **Contract Negotiations:** Risk-adjusted valuations using credible intervals\n",
    "\n",
    "### Extensions:\n",
    "\n",
    "1. Add pitcher data with position-specific feature sets\n",
    "2. Multi-level hierarchy: Position → League → Organization\n",
    "3. Time-varying effects: Model age curves within Bayesian framework\n",
    "4. Causal inference: Treatment effects for development interventions\n",
    "5. Survival analysis: Time-to-MLB-arrival using Bayesian AFT models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "bayes_model.save(filename='bayesian_prospect_model_2024')\n",
    "\n",
    "print(\"\\n✓ Model saved successfully!\")\n",
    "print(\"\\nTo load in production:\")\n",
    "print(\">>> model = BayesianProspectModel()\")\n",
    "print(\">>> model.load('bayesian_prospect_model_2024')\")\n",
    "print(\">>> predictions = model.predict(new_data, positions)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
